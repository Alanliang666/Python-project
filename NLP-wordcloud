!pip install jieba # jieba 中文斷詞套件
!pip install wordcloud # wordcloud 文字雲視覺化套件
!pip install matplotlib # matplotlib 畫圖工具套件# txt檔案路徑

text_file_path = "stocknews.txt"
with open(text_file_path,"r") as fn:
  lines = fn.readlines()
  lines = list(map(lambda x: x.strip() , lines))

token1 = list(map(lambda x: list(jieba.cut(str(x),HMM=False)),lines))


token2 = list(map(lambda x: list(jieba.cut(str(x),cut_all=True,HMM=False)),lines))

token3 = list(map(lambda x: list(jieba.cut_for_search(str(x),HMM=False)),lines))


word_count = {}
for sent in token1:
 for word in sent:
 if word not in word_count:
      word_count[word] = 0
    word_count[word] += 1



word_count_5 = {}

for word, count in word_count.items():
 if count > 5 :
    word_count_5[word] = count

print(word_count_5)

import wordcloud
from wordcloud import WordCloud
import matplotlib
import matplotlib.pyplot as plt

# 下載中文字型檔
!wget https://github.com/odek53r/Data-Science-Camp/raw/main/SourceHanSerifK-Light.otf

wordcloud = WordCloud(
        background_color = 'white',
        font_path = '/content/SourceHanSerifK-Light.otf', # 放入中文字型檔路徑
        colormap=matplotlib.cm.cubehelix,
        width = 1600,
        height = 800,
        margin = 2)

# wordcloud 套件 Input 需放入詞頻統計的 dict 型態變數
wordcloud = wordcloud.generate_from_frequencies(word_count_5) 
plt.figure(figsize=(20,10), facecolor='k')
plt.imshow(wordcloud)
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()
